{
 "metadata": {
  "name": "",
  "signature": "sha256:169980f2c28054a09e2feab3e194d130165ed3a3fd54bbed84c012f150e1812e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import * \n",
      "css_styles()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# IOOS System Test - Theme 2\n",
      "\n",
      "## CoscoBusan\n",
      "* November 7, 2007 at 8:27 AM the container ship M/V Cosco Busan strikes the San Francisco Bay Bridge tearing a 100 ft. long gash in its hull over the fuel tanks.\n",
      "* 50,000 gals of bunker fuel discharges into the Bay in approximately 10 seconds.\n",
      "* The USCG and DFG are notified of an incident and respond immediately, on-scene in 50 minutes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylab import *\n",
      "from IPython.display import HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Geographic subset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bounding_box = [ -123.38, 37.05, -121.53, 38.37]  # San Francisco Bay and surrounding waters\n",
      "\n",
      "\"Geographic subset: {!s}\".format(bounding_box)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Temporal subset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime\n",
      "start_date = datetime(2007,11,1)\n",
      "start_date_string = start_date.strftime('%Y-%m-%d %H:00')\n",
      "\n",
      "end_date = datetime(2007,11,14)\n",
      "end_date_string = end_date.strftime('%Y-%m-%d %H:00')\n",
      "\n",
      "\"Temporal subset: ( {!s} to {!s} )\".format(start_date_string, end_date_string)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Define all known the CSW endpoints"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# https://github.com/ioos/system-test/wiki/Service-Registries-and-Data-Catalogs\n",
      "known_csw_servers = ['http://data.nodc.noaa.gov/geoportal/csw',\n",
      "                     'http://www.nodc.noaa.gov/geoportal/csw',\n",
      "                     'http://www.ngdc.noaa.gov/geoportal/csw',\n",
      "                     'http://cwic.csiss.gmu.edu/cwicv1/discovery',\n",
      "                     'http://geoport.whoi.edu/geoportal/csw',\n",
      "                     'https://edg.epa.gov/metadata/csw',\n",
      "                     'http://cmgds.marine.usgs.gov/geonetwork/srv/en/csw',\n",
      "                     'http://cida.usgs.gov/gdp/geonetwork/srv/en/csw',\n",
      "                     'http://geodiscover.cgdi.ca/wes/serviceManagerCSW/csw',\n",
      "                     'http://geoport.whoi.edu/gi-cat/services/cswiso',\n",
      "                     'https://data.noaa.gov/csw',\n",
      "                     ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Construct CSW Filters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib import fes\n",
      "def fes_date_filter(start_date='1900-01-01',stop_date='2100-01-01',constraint='overlaps'):\n",
      "    if constraint == 'overlaps':\n",
      "        start = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=start_date)\n",
      "        stop = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=stop_date)\n",
      "    elif constraint == 'within':\n",
      "        start = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=start_date)\n",
      "        stop = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=stop_date)\n",
      "    return fes.And([start, stop])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Geographic filters\n",
      "geographic_filter = fes.BBox(bbox=bounding_box)\n",
      "\n",
      "# Temporal filters\n",
      "temporal_filter = fes_date_filter(start_date_string, end_date_string)\n",
      "\n",
      "filters = fes.And([geographic_filter, temporal_filter])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### The actual CSW filter POST envelope looks like this"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib.etree import etree\n",
      "print etree.tostring(filters.toXML(), pretty_print=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Filter out CSW servers that do not support a BBOX query"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib.csw import CatalogueServiceWeb\n",
      "bbox_endpoints = []\n",
      "for url in known_csw_servers:\n",
      "    queryables = []\n",
      "    try:\n",
      "        csw = CatalogueServiceWeb(url, timeout=20)\n",
      "    except BaseException:\n",
      "        print \"Failure - %s - Timed out\" % url\n",
      "    if \"BBOX\" in csw.filters.spatial_operators:\n",
      "        print \"Success - %s - BBOX Query supported\" % url\n",
      "        bbox_endpoints.append(url)    \n",
      "    else:\n",
      "        print \"Failure - %s - BBOX Query NOT supported\" % url"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Query CSW Servers using filters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles = []\n",
      "urls = []\n",
      "service_types = []\n",
      "servers = []\n",
      "for url in bbox_endpoints:\n",
      "    print \"*\", url\n",
      "    try:\n",
      "        csw = CatalogueServiceWeb(url, timeout=20)\n",
      "        csw.getrecords2(constraints=[filters], maxrecords=200, esn='full')\n",
      "        for record, item in csw.records.items():\n",
      "            try:\n",
      "                # Get title\n",
      "                if len(item.title) > 80:\n",
      "                   title = \"{!s}...{!s}\".format(item.title[0:40], item.title[-40:])\n",
      "                else:\n",
      "                    title = item.title\n",
      "                service_url, scheme = next(((d['url'], d['scheme']) for d in item.references), None)\n",
      "                if service_url:    \n",
      "                    print \"    [x] {!s}\".format(title)\n",
      "                    titles.append(item.title)\n",
      "                    urls.append(service_url)\n",
      "                    service_types.append(scheme)\n",
      "                    servers.append(url)\n",
      "            except:\n",
      "                continue\n",
      "    except BaseException as e:\n",
      "        print \"    [-] FAILED: {!s}\".format(e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### What service are available?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "srvs = pd.DataFrame(zip(titles, urls, service_types, servers), columns=(\"Title\", \"URL\", \"Service Type\", \"Server\"))\n",
      "srvs = srvs.drop_duplicates()\n",
      "pd.set_option('display.max_rows', 10)\n",
      "srvs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### What types of service are available"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(srvs.groupby(\"Service Type\").size(), columns=(\"Number of services\",))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"error\" style=\"text-align: center\"><strong>SOS and DAP Servers are not properly identified</strong><br />One can not tell (programatically) what the \"urn:x-esri:specification:ServiceType:distribution:url\" scheme actually is.</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# SOS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_sos(x):\n",
      "    d = x.lower()\n",
      "    if \"sos\" in d and \"dods\" not in d:\n",
      "        return x\n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sos_servers = filter(None, srvs[\"URL\"].map(find_sos))\n",
      "sos_servers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"error\" style=\"text-align: center\"><strong>52N SOS Link is not correct</strong> - <a href=\"https://github.com/ioos/system-test/issues/189\">Issue #189</a><br />http://sos.cencoos.org/sos/sos/json should be referencing http://sos.cencoos.org/sos/sos as the SOS server.</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Set some variables to pull from SOS servers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "variables_to_query = [\"sea_water_temperature\", \"surface_temperature_anomaly\", \"air_temperature\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Pull out all observation from all SOS servers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyoos.collectors.ioos.swe_sos import IoosSweSos\n",
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "from pyoos.collectors.ndbc.ndbc_sos import NdbcSos\n",
      "from owslib.ows import ExceptionReport\n",
      "from datetime import timedelta\n",
      "from copy import copy\n",
      "from StringIO import StringIO\n",
      "\n",
      "sos_dfs = []\n",
      "for sos in sos_servers:\n",
      "    if \"co-ops\" in sos.lower() or \"ndbc\" in sos.lower():\n",
      "        \n",
      "        # CSV Output\n",
      "    \n",
      "        if \"co-ops\" in sos.lower():\n",
      "            # Use the COOPS collector\n",
      "            collector = CoopsSos()\n",
      "        elif \"ndbc\" in sos.lower():\n",
      "            # Use the NDBC collector\n",
      "            collector = NdbcSos()\n",
      "        for v in variables_to_query:\n",
      "            collector.filter(variables=[v])\n",
      "            collector.filter(bbox=bounding_box)\n",
      "            new_start = copy(start_date)\n",
      "            new_end   = copy(start_date)\n",
      "\n",
      "            # Hold dataframe for periodic concat\n",
      "            v_frame = None\n",
      "\n",
      "            while new_end < end_date:\n",
      "                new_end = min(end_date, new_start + timedelta(days=1))\n",
      "                collector.filter(start=new_start)\n",
      "                collector.filter(end=new_end)\n",
      "                try:\n",
      "                    print \"Collecting from {!s}: ({!s} -> {!s})\".format(sos, new_start, new_end)\n",
      "                    data = collector.raw()\n",
      "                    new_frame = pd.DataFrame.from_csv(StringIO(data))\n",
      "                    new_frame = new_frame.reset_index()\n",
      "                    if v_frame is None:\n",
      "                        v_frame = new_frame\n",
      "                    else:\n",
      "                        v_frame = pd.concat([v_frame, new_frame])\n",
      "                        v_frame = v_frame.drop_duplicates()\n",
      "                except ExceptionReport as e:\n",
      "                    print \"  [-] Error obtaining {!s} from {!s} - Message from server: {!s}\".format(v, sos, e)\n",
      "                    continue\n",
      "                finally:\n",
      "                    new_start = new_end\n",
      "\n",
      "            if v_frame is not None:\n",
      "                sos_dfs.append(v_frame)\n",
      "    \n",
      "    else:\n",
      "        # Use the generic IOOS SWE collector\n",
      "        try:\n",
      "            collector = IoosSweSos(sos)\n",
      "        except BaseException as e:\n",
      "            print \"[-]  Could not process {!s}.  Reason: {!s}\".format(sos, e)\n",
      "            continue\n",
      "            \n",
      "        for v in variables_to_query:\n",
      "            collector.filter(variables=[v])\n",
      "            collector.filter(bbox=bounding_box)\n",
      "            collector.filter(start=start_date)\n",
      "            collector.filter(end=end_date)\n",
      "            collector.filter(variables=[v])\n",
      "            try:\n",
      "                data = collector.collect()\n",
      "                print data\n",
      "            except BaseException as e:\n",
      "                print \"[-]  Could not process {!s}.  Reason: {!s}\".format(sos, e)\n",
      "                continue\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"success\" style=\"text-align: center\"><strong>NOTE</strong><br />We are only plotting the first variable retrieved back from the SOS server.  The following graphs could be in a loop.</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.max_rows', 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Number of measurments per sensor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(sos_dfs[0].groupby(\"sensor_id\").size(), columns=(\"Number of measurments\",))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graphing_frame = sos_dfs[0].pivot(index='date_time', columns='sensor_id', values=sos_dfs[0].columns[-1])\n",
      "graphing_frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "for col in graphing_frame.columns:\n",
      "    fig, axes = plt.subplots(figsize=(20,5))\n",
      "    graphing_frame[col].dropna().plot(title=col, color='m')\n",
      "    axes.set_xlabel(\"Time (UTC)\")\n",
      "    axes.set_ylabel(sos_dfs[0].columns[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# DAP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_dap(x):\n",
      "    d = x.lower()\n",
      "    if (\"dap\" in d or \"dods\" in d) and \"tabledap\" not in d and \"sos\" not in d:\n",
      "        return x\n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "dap_servers = filter(None, srvs[\"URL\"].map(find_dap))\n",
      "dap_servers = map(lambda x: os.path.splitext(x)[0], dap_servers)\n",
      "dap_servers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Try to temperature data from all of the DAP endpoints at the time of the spill"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pytz\n",
      "spill_time = datetime(2007, 11, 7, 8, 47, tzinfo=pytz.timezone(\"US/Pacific\"))\n",
      "\"Spill time: {!s}\".format(spill_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "import iris.plot as iplt\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "variables = lambda cube: cube.standard_name in variables_to_query\n",
      "constraint = iris.Constraint(cube_func=variables)\n",
      "\n",
      "\n",
      "\n",
      "def iris_grid_plot(cube_slice, name=None):\n",
      "    plt.figure(figsize=(12, 8))\n",
      "    lat = cube_slice.coord(axis='Y').points\n",
      "    lon = cube_slice.coord(axis='X').points\n",
      "    time = cube_slice.coord('time')[0]\n",
      "    plt.subplot(111, aspect=(1.0 / cos(mean(lat) * pi / 180.0)))\n",
      "    plt.pcolormesh(lon, lat, ma.masked_invalid(cube_slice.data));\n",
      "    plt.colorbar()\n",
      "    plt.grid()\n",
      "    date = time.units.num2date(time.points)\n",
      "    date_str = date[0].strftime('%Y-%m-%d %H:%M:%S %Z')\n",
      "    plt.title('%s: %s: %s' % (name, cube_slice.long_name, date_str));\n",
      "    plt.show()\n",
      "\n",
      "for dap in dap_servers:\n",
      "    print \"[*]  {!s}\".format(dap)\n",
      "    try:\n",
      "        cube = iris.load_cube(dap, constraint)\n",
      "    except Exception as e:\n",
      "        print \"    [-]  Could not load: {!s}\".format(e)\n",
      "        continue\n",
      "    \n",
      "    print \"    [-]  Identified as a Grid\"\n",
      "    print \"    [-]  {!s}\".format(cube.attributes[\"title\"])\n",
      "    try:\n",
      "        if len(cube.shape) > 2:\n",
      "            try:\n",
      "                cube.coord(axis='T').rename('time')\n",
      "            except:\n",
      "                pass\n",
      "            time_dim   = cube.coord('time')\n",
      "            time_value = time_dim.units.date2num(spill_time)\n",
      "            time_index = time_dim.nearest_neighbour_index(time_value)\n",
      "            time_pts   = time_dim.points[time_index]\n",
      "    \n",
      "            if len(cube.shape) == 4:\n",
      "                cube = cube.extract(iris.Constraint(time=time_pts))\n",
      "                cube = cube[-1, ::1, ::1]\n",
      "            elif len(cube.shape) == 3:\n",
      "                cube = cube.extract(iris.Constraint(time=time_pts))\n",
      "                cube = cube[::1, ::1]\n",
      "        elif len(cube.shape) == 2:\n",
      "            cube = cube[::1, ::1]\n",
      "        else:\n",
      "            raise ValueError(\"Dimensions do not adhere to plotting requirements\")\n",
      "        iris_grid_plot(cube, cube.attributes[\"title\"])\n",
      "            \n",
      "    except ValueError as e:\n",
      "        print \"    [-]  Could not plot: {!s}\".format(e)\n",
      "        continue    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}